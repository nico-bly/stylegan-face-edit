{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bimodal VAE (+PCA term?)\n",
    "\n",
    "As observed in the latent space, we see that the when projecting on a direction the images are organized as a sum of two gaussians, one centered on one half of the hyperplane and the other in the second one. This is what we will change the traditional VAE that has an a priori that is one gaussian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import generate_nb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import dnnlib\n",
    "import legacy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.optim import Adam\n",
    "import projector_nb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "network = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with dnnlib.util.open_url(network) as fp:\n",
    "        G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device)\n",
    "        \n",
    "def generate_samples(G, num_samples):\n",
    "    z_samples = np.random.RandomState().randn(num_samples, 512).astype(np.float32) \n",
    "    \n",
    "    w_samples = G.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "    w_samples = w_samples.cpu().numpy()\n",
    "    w_samples = w_samples[:,0,:]\n",
    "\n",
    "    return w_samples\n",
    "\n",
    "\n",
    "w_samples_ae = generate_samples(G, 100)\n",
    "\n",
    "# Define your data preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('standard', StandardScaler()),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "w_samples_scaled = preprocessing_pipeline.fit_transform(w_samples_ae)\n",
    "w_samples_scaled = np.clip(w_samples_scaled, 0, 1)\n",
    "print(np.min(w_samples_scaled))\n",
    "print(np.max(w_samples_scaled))\n",
    "dataset = TensorDataset(torch.tensor(w_samples_scaled, dtype=torch.float32))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "input_dim = 512\n",
    "hidden_dim = 256\n",
    "latent_dim = 2\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim//4),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim//4, latent_dim * 4)  # 4 for mean1, log_var1, mean2, log_var2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mean1, log_var1, mean2, log_var2 = torch.chunk(h, 4, dim=1)\n",
    "        return mean1, log_var1, mean2, log_var2\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim//4),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim//4, hidden_dim//2),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def reparameterize(self, mean1, log_var1, mean2, log_var2):\n",
    "        std1 = torch.exp(0.5 * log_var1)\n",
    "        eps1 = torch.randn_like(std1)\n",
    "        z1 = mean1 + eps1 * std1\n",
    "        \n",
    "        std2 = torch.exp(0.5 * log_var2)\n",
    "        eps2 = torch.randn_like(std2)\n",
    "        z2 = mean2 + eps2 * std2\n",
    "        \n",
    "        return z1, z2\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean1, log_var1, mean2, log_var2 = self.encode(x)\n",
    "        z1, z2 = self.reparameterize(mean1, log_var1, mean2, log_var2)\n",
    "        z = z1+z2\n",
    "        print(z.shape)\n",
    "        x_recon = self.decode(z)  \n",
    "        return x_recon, mean1, log_var1, mean2, log_var2,z\n",
    "\n",
    "def orthogonality_constraint(z):\n",
    "    z_prod = torch.matmul(z.T,z)\n",
    "    identity = torch.eye(z_prod.size(0)).to(device)\n",
    "    ortho_loss = torch.norm(z_prod - identity, p='fro')\n",
    "    return ortho_loss\n",
    "\n",
    "def loss_function(recon_x, x,mean1, log_var1, mean2, log_var2,z,beta=200.0,alpha=100.0):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    print(\"BCE Loss is:\", BCE)\n",
    "\n",
    "    # KL divergence for the sum of two Gaussians\n",
    "    KLD1 = -0.5 * torch.sum(1 + log_var1 - mean1.pow(2) - log_var1.exp())\n",
    "    KLD2 = -0.5 * torch.sum(1 + log_var2 - mean2.pow(2) - log_var2.exp())\n",
    "    KLD = KLD1 + KLD2\n",
    "    print(\"beta x KLD is :\", beta*KLD)\n",
    "\n",
    "    # orthopenalty\n",
    "    \n",
    "    orthogonality_loss =  orthogonality_constraint(z) \n",
    "    print(\"alpha x orthogonality loss is:\", alpha*orthogonality_loss)\n",
    "    return BCE + beta*KLD + alpha*orthogonality_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4721.1890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(1637.9420, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3581.7268, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4727.5225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(1488.6875, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4227.0918, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4713.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(1251.2552, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3590.6963, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4666.1455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(1046.7148, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3716.4023, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4685.9160, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(859.6860, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2738.2031, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4702.7451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(610.5293, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3255.1665, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1207.7980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(160.4919, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(383.6419, grad_fn=<MulBackward0>)\n",
      "Epoch 1, Loss: 1751.9317626953125\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4702.1758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(391.4793, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4205.9058, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4706.0391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(344.1747, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3151.9553, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4665.7119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(277.9033, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3639.7285, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4736.7988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(258.6540, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3825.5386, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4672.6255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(236.7371, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2824.2200, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4717.4883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(253.5870, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3293.5193, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1213.6859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(61.0403, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(628.1751, grad_fn=<MulBackward0>)\n",
      "Epoch 2, Loss: 1902.9013671875\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4636.4233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(265.1058, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(5743.1406, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4765.3389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(308.4845, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(5764.9355, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4758.8481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(364.4807, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4127.7598, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4710.7578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(438.4912, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3754.6794, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4695.9995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(547.8173, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(5114.6973, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4686.7646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(613.9553, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(5016.6479, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1160.8136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(180.6304, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(1153.0298, grad_fn=<MulBackward0>)\n",
      "Epoch 3, Loss: 2494.4736328125\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4725.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(860.8419, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2550.9739, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4641.7056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(805.8200, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3222.6326, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4688.8477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(743.5820, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3204.1882, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4716.3257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(693.4800, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2711.7080, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4695.2651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(579.1726, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3153.3706, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4745.7129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(510.7084, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4151.5786, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1204.4430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(119.1104, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(1084.1326, grad_fn=<MulBackward0>)\n",
      "Epoch 4, Loss: 2407.68603515625\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4724.6851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(399.9016, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3989.6855, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4616.2690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(381.6107, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4055.8772, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4698.1636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(368.4764, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4037.1526, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4681.9927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(380.1324, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3474.4824, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4744.7593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(377.7780, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3560.1216, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4762.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(392.5471, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4380.6284, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1175.4336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(105.1260, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(338.3036, grad_fn=<MulBackward0>)\n",
      "Epoch 5, Loss: 1618.8631591796875\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4678.9429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(427.5376, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3222.0073, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4655.0210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(442.0804, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(6026.5161, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4705.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(478.6609, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2096.4775, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4733.4932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(523.1071, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3371.8789, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4765.8979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(508.8206, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3095.1670, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4702.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(516.3914, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4347.7949, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1163.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(120.2078, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(1864.8569, grad_fn=<MulBackward0>)\n",
      "Epoch 6, Loss: 3148.6474609375\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4709.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(557.6915, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3730.6030, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4715.0854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(619.6588, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3895.7234, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4753.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(675.8597, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3519.2666, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4682.0034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(706.0676, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(1450.8955, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4685.0488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(704.2861, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2757.1443, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4689.7939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(649.8782, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2835.9270, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1165.6222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(137.1829, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(616.1136, grad_fn=<MulBackward0>)\n",
      "Epoch 7, Loss: 1918.918701171875\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4718.4585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(540.6659, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4682.0615, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4674.4619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(513.0290, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4187.4888, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4663.8369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(478.3381, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2859.1565, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4696.5889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(409.6530, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4088.7378, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4721.0439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(420.3031, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4811.2686, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4771.2588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(391.6973, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2962.4700, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1157.9478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(88.2670, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(638.0557, grad_fn=<MulBackward0>)\n",
      "Epoch 8, Loss: 1884.2705078125\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4653.1782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(377.8044, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(5224.1753, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4682.3462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(403.9242, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4729.4492, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4768.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(453.6470, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3132.8264, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4741.4639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(476.5453, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4368.2388, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4686.0918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(547.0349, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2876.5776, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4706.6289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(552.8146, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2070.5991, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1163.7327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(145.9727, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(1027.0762, grad_fn=<MulBackward0>)\n",
      "Epoch 9, Loss: 2336.78173828125\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4733.6670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(615.0324, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3591.6538, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4644.3154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(578.6342, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3760.1899, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4650.9897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(558.3228, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(4535.2285, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4736.8110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(588.8350, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(2969.2441, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4676.4863, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(567.5701, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(3485.4167, grad_fn=<MulBackward0>)\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 2])\n",
      "BCE Loss is: tensor(4795.8286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(535.9788, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(5067.7427, grad_fn=<MulBackward0>)\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 2])\n",
      "BCE Loss is: tensor(1169.9155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "beta x KLD is : tensor(120.8086, grad_fn=<MulBackward0>)\n",
      "alpha x orthogonality loss is: tensor(851.1958, grad_fn=<MulBackward0>)\n",
      "Epoch 10, Loss: 2141.919921875\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data in dataloader:\n",
    "        x = data[0].to(device)\n",
    "        print(x.shape)\n",
    "        x_recon, mean1, log_var1, mean2, log_var2,z= vae(x)\n",
    "    \n",
    "        loss = loss_function(x_recon, x,mean1, log_var1, mean2, log_var2,z,beta=500.0,alpha=100.0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "torch.save(vae.state_dict(), 'vae_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stylegan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
